# -*- coding: utf-8 -*-
"""Proyek Akhir: Sistem Rekomendasi BBC News.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cZMZT6m1mtCuM2R54YmvVelp7DY10vgl

## Import Library

Kode berikut digunakan untuk mengimpor berbagai pustaka yang diperlukan dalam pengembangan model machine learning untuk sistem rekomendasi. Setiap library memiliki fungsi khusus yang mendukung proses preprocessing data, pembuatan model, evaluasi, serta visualisasi hasil.
"""

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from google.colab import files
import string
import re
import nltk
import pandas as pd
import numpy as np

nltk.download('punkt_tab')
nltk.download('stopwords')

"""## Data Loading

Pada tahapan ini, dataset akan diunduh dari Kaggle dan kemudian dibaca menggunakan pandas. Pandas merupakan library Python yang digunakan untuk memanipulasi dan menganalisis data dalam bentuk tabel (DataFrame).

### Get data from kaggle

Kode berikut digunakan untuk mengunggah berkas API key dari Kaggle (kaggle.json) dan mengunduh dataset yang diperlukan. Setelah proses pengunduhan selesai, dataset diekstrak (unzip) agar dapat dibaca menggunakan pandas.
"""

files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download gpreda/bbc-news

! unzip bbc-news.zip

"""### Load Dataset

Setelah dataset berhasil diunduh dan diekstrak, langkah selanjutnya adalah membaca file dataset menggunakan fungsi .read_csv() dari library pandas. Fungsi ini digunakan untuk memuat data dari file CSV ke dalam bentuk DataFrame.
"""

news = pd.read_csv("bbc_news.csv")
news.head()

"""## Exploratory Data Analysis

Pada tahap ini dilakukan proses *Exploratory Data Analysis* (EDA) yang bertujuan untuk:

- Menganalisis karakteristik masing-masing fitur dalam dataset.
- Mengidentifikasi dan menangani *missing value* serta data duplikat.
- Melakukan analisis terhadap fitur-fitur untuk menentukan pendekatan pemodelan yang paling sesuai.

### Variable Description

Melakukan pemeriksaan informasi dasar pada dataset menggunakan fungsi info() untuk mengetahui tipe data, jumlah nilai non-null, serta penggunaan memori pada setiap kolom.
"""

news.info()

"""### Check for Missing and Duplicate Values

Melakukan pemeriksaan terhadap *missing value* dan data duplikat pada dataset guna memastikan kualitas data sebelum memasuki tahap analisis dan pemodelan. Berdasarkan hasil pemeriksaan, tidak ditemukan adanya *missing value* maupun data duplikat, sehingga tahap pembersihan data tidak diperlukan.
"""

print("Total missing value: ", news.isnull().sum())
print("Total duplicates: ", news.duplicated().sum())

"""### Univariate Analysis

Pada tahap ini dilakukan Univariate analysis untuk memahami distribusi dan karakteristik masing-masing fitur secara terpisah.

Kode berikut digunakan untuk mengonversi tipe data pada fitur pubDate menjadi tipe data datetime64, agar dapat dilakukan analisis berbasis waktu secara lebih akurat dan efisien.
"""

news["pubDate"] = pd.to_datetime(news["pubDate"])
print(news["pubDate"].dtype)

news.head()

"""Kode berikut digunakan untuk memperoleh informasi mengenai tanggal pertama dan terakhir berita dipublikasikan dalam dataset."""

print("Start Publish : ", news["pubDate"].min())
print("End Publish : ", news["pubDate"].max())

"""Melakukan pengelompokan data berita berdasarkan tahun publikasinya untuk memperoleh jumlah berita yang dipublikasikan pada setiap tahun."""

total_news_per_year = news["pubDate"].dt.year.value_counts().sort_index()
total_news_per_year

"""## Data Preparation

Pada tahap ini, dataset dipersiapkan agar siap digunakan dalam proses pemodelan machine learning. Beberapa langkah penting yang dilakukan antara lain:

- Seleksi data berita tahun 2024, yang terdiri dari 14.761 entri berita.
- Proses text processing, meliputi pembersihan teks seperti penghapusan tanda baca, huruf kapital, dan karakter-karakter yang tidak penting.
- Ekstraksi fitur menggunakan TF-IDF (Term Frequency-Inverse Document Frequency) untuk merepresentasikan konten teks dalam bentuk vektor numerik.
- Perhitungan derajat kesamaan antar berita menggunakan teknik cosine similarity untuk mengukur tingkat kemiripan konten antar artikel.
"""

news_2024 = news[news["pubDate"].dt.year == 2024]
news_2024.head()

"""### Text Processing

Pada tahap ini dilakukan proses text processing untuk membersihkan dan mempersiapkan teks berita sebelum diekstraksi menjadi fitur numerik. Langkah-langkah preprocessing ini penting agar model dapat memahami isi teks secara konsisten dan akurat.

Kode berikut merupakan sebuah fungsi yang digunakan untuk membersihkan teks dari tanda baca, huruf kapital, serta karakter-karakter yang tidak penting.
"""

def cleaningText(text):
  text = re.sub(r'@[A-Za-z0-9]+', '', text)
  text = re.sub(r'#[A-Za-z0-9]+', '', text)
  text = re.sub(r'RT[\s]', '', text)
  text = re.sub(r"http\S+", '', text)
  text = re.sub(r'[0-9]+', '', text)
  text = re.sub(r'[^\w\s]', '', text)

  text = text.replace('\n', ' ')
  text = text.translate(str.maketrans('', '', string.punctuation))
  text = text.strip(' ')
  return text

def casefoldingText(text):
  text = text.lower()
  return text

"""Kode berikut digunakan untuk menerapkan fungsi pembersih teks yang telah dibuat sebelumnya pada fitur ```description```. Tujuan dari proses ini adalah untuk menyederhanakan isi teks agar menjadi lebih konsisten dan terstruktur, sehingga memudahkan dalam tahap-tahap selanjutnya seperti ekstraksi fitur dan perhitungan kesamaan antar teks."""

news_to_clean = news_2024[["description"]].copy()


news_to_clean["description_clean"] = news_to_clean["description"].apply(cleaningText)
news_to_clean["description_casefolding"] = news_to_clean["description_clean"].apply(casefoldingText)

news_to_clean.head()

"""### Create new dataframe for Dataset

Pada tahap ini, dibuat dataset akhir yang berisi dua kolom utama dari data berita tahun 2024: title dan description (yang telah melalui proses pembersihan). Dataset inilah yang akan digunakan sebagai input pada tahap selanjutnya, yaitu ekstraksi fitur menggunakan TF-IDF dan perhitungan kesamaan antar teks menggunakan cosine similarity.
"""

dataset = pd.DataFrame({
    "title": news_2024["title"],
    "description": news_to_clean["description_casefolding"]
})

dataset

"""### Feature Extraction (TF-IDF)

Ekstraksi fitur dilakukan menggunakan TF-IDF untuk mengubah teks pada kolom description menjadi representasi numerik. TfidfVectorizer dikonfigurasi dengan penghapusan stopwords Bahasa Inggris, max_df=0.8, min_df=10, dan max_features=1000. Hasilnya berupa matriks TF-IDF yang merepresentasikan setiap dokumen berdasarkan kata-kata pentingnya dan siap digunakan untuk perhitungan cosine similarity.
"""

tfidf = TfidfVectorizer(
    stop_words = "english",
    max_df=0.8,
    min_df=10,
    max_features=1000,
)

tfidf_matrix = tfidf.fit_transform(dataset["description"])

print("TF-IDF Matrix shape: ", tfidf_matrix.shape)
print(tfidf_matrix.toarray())

"""Kode berikut digunakan untuk membuat DataFrame yang menghubungkan judul berita dengan setiap kata fitur yang diekstrak dari kolom description menggunakan TF-IDF. DataFrame ini berguna untuk menganalisis dan memvisualisasikan korelasi antara judul berita dengan kata-kata penting yang muncul di deskripsi, sehingga dapat membantu memahami representasi teks dan kontribusi kata-kata terhadap masing-masing berita."""

tfidf_matrix_df = pd.DataFrame(
    tfidf_matrix.toarray(),
    columns=tfidf.get_feature_names_out(),
    index=dataset.title
)

tfidf_matrix_df.sample(5)

"""### Cosine Similarity

Pada tahap ini dilakukan perhitungan cosine similarity antar dokumen berdasarkan matriks TF-IDF yang telah dihasilkan sebelumnya. Cosine similarity digunakan untuk mengukur tingkat kemiripan antar berita dengan menghitung sudut kosinus antara dua vektor teks. Nilai kemiripan berkisar antara 0 (tidak mirip) hingga 1 (identik). Hasil dari perhitungan ini akan digunakan untuk merekomendasikan berita yang memiliki konten serupa.
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Pada tahap ini, dibuat sebuah DataFrame dari hasil perhitungan cosine similarity untuk memudahkan dalam menampilkan dan menganalisis sampel kemiripan antar berita. DataFrame ini memungkinkan kita untuk melihat tingkat kesamaan antara satu berita dengan berita lainnya dalam format tabel yang lebih mudah dipahami dan digunakan untuk proses rekomendasi.


"""

cosine_sim_df = pd.DataFrame(
    cosine_sim,
    index=dataset.title,
    columns=dataset.title,
)

print("Shape: ", cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## Model Development Content-Based Filtering

Pada tahap ini dikembangkan fungsi rekomendasi berita berbasis Content-Based Filtering (CBF) yang memanfaatkan matriks cosine similarity antar berita.
Fungsi news_recommendation bekerja dengan cara:

- Menerima input berupa judul berita (news_title) yang ingin dicari rekomendasinya.
- Memastikan judul berita tersebut tersedia di data similarity.
- Mengurutkan dan mengambil k berita terdekat berdasarkan nilai kemiripan tertinggi dari matriks cosine similarity.
- Menghapus judul berita input dari hasil rekomendasi agar tidak muncul sebagai rekomendasi terhadap dirinya sendiri.
- Mengembalikan DataFrame yang berisi judul berita rekomendasi beserta deskripsinya.

Fungsi ini memungkinkan pengguna mendapatkan rekomendasi berita yang memiliki konten serupa dengan berita yang dipilih, sehingga meningkatkan pengalaman pengguna dalam menemukan berita relevan.
"""

def news_recommendation(news_title, similarity_data=cosine_sim_df, items=dataset[["title", "description"]], k=5):
  if news_title not in similarity_data.columns:
    return f"News title '{news_title}' is not found in the dataset."

  index = similarity_data[news_title].to_numpy().argsort()[-k-1:][::-1]

  closest = similarity_data.columns[index]

  closest = closest.drop(news_title, errors="ignore")

  return pd.DataFrame(closest, columns=["title"]).merge(items, on="title").head(k)

"""Kode berikut digunakan untuk menjalankan fungsi rekomendasi yang memberikan daftar berita lain yang relevan berdasarkan judul berita input."""

news_recommendation("Tom Cruise abseils off stadium roof in daring Olympic finale")

"""## Evaluation

Pada tahap ini, model rekomendasi dievaluasi menggunakan metrik Precision@k dan Average Precision. Kedua metrik ini berfungsi untuk mengukur sejauh mana model mampu memberikan rekomendasi yang relevan dan berguna bagi pengguna.

Kode berikut mendefinisikan ground truth berupa daftar judul berita yang relevan sebagai acuan kebenaran, kemudian menjalankan fungsi rekomendasi news_recommendation berdasarkan judul berita input tertentu. Hasil rekomendasi disimpan dalam variabel recommendations dalam bentuk daftar judul berita.
"""

ground_truth = ["Actor Chance Perdomo dies in motorcycle accident, aged 27",
                "Sebastián Piñera: Former president of Chile dies in helicopter crash"]

recommendations_df = news_recommendation("Tom Cruise abseils off stadium roof in daring Olympic finale")
recommendations = recommendations_df["title"].tolist()

"""### Precision@K

Kode berikut mendefinisikan fungsi precision_at_k untuk menghitung Precision@k, yaitu proporsi judul berita dalam rekomendasi top-k yang juga terdapat pada riwayat atau ground truth pengguna. Fungsi ini membandingkan daftar rekomendasi dengan data kebenaran untuk mengukur ketepatan hasil rekomendasi. Hasil evaluasi dengan menggunakan Precision@5 pada contoh ini adalah 0.40 (40%).
"""

def precision_at_k(user_history, recommended_titles, k=5):
    user_history_set = set([title.strip().lower() for title in user_history])
    recommended_top_k = [title.strip().lower() for title in recommended_titles[:k]]

    hits = sum(1 for title in recommended_top_k if title in user_history_set)
    return hits / k

precision = precision_at_k(ground_truth, recommendations)
print(f"Precision@5: {precision:.2f}")

"""### Average Precision

Kode berikut mendefinisikan fungsi average_precision untuk menghitung Average Precision, yaitu rata-rata presisi pada posisi di mana item relevan ditemukan dalam daftar rekomendasi. Fungsi ini menjumlahkan nilai presisi setiap kali rekomendasi yang relevan muncul, lalu membaginya dengan total item relevan dalam ground truth. Hasil evaluasi menggunakan Average Precision pada contoh ini adalah 0.83 (83%).
"""

def average_precision(user_history, recommended_titles):
  hits = 0
  sum_precision = 0

  for i, title in enumerate(recommended_titles):
    if title in user_history:
      hits += 1
      precision_at_i = hits / (i + 1)
      sum_precision += precision_at_i

    if hits == 0:
      return 0.0

  return sum_precision / len(user_history)

ap = average_precision(ground_truth, recommendations)
print(f"Average Precision: {ap:.2f}")